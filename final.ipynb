{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff936d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "final.py\n",
    "\n",
    "Robust vanilla CLIP fine-tuning (FP32) with defensive checks:\n",
    " - clamps learned logit_scale each step\n",
    " - per-sample preprocessing checks (skip bad samples within a batch)\n",
    " - if a batch produces NaNs, isolates and logs offending samples, saves previews\n",
    " - gradient clipping and conservative default LR\n",
    " - saves per-epoch predictions CSV and checkpoints\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import argparse\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import clip\n",
    "import traceback\n",
    "\n",
    "# torchvision optional (for saving image previews)\n",
    "try:\n",
    "    import torchvision\n",
    "    _TORCHVISION_AVAILABLE = True\n",
    "except Exception:\n",
    "    _TORCHVISION_AVAILABLE = False\n",
    "\n",
    "# --------------------------\n",
    "# Dataset\n",
    "# --------------------------\n",
    "class CsvImageTextDataset(Dataset):\n",
    "    def __init__(self, csv_file, data_root, preprocess):\n",
    "        self.samples = []\n",
    "        with open(csv_file, newline='', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            if \"image_path\" not in reader.fieldnames or \"caption\" not in reader.fieldnames:\n",
    "                raise ValueError(f\"CSV {csv_file} must contain 'image_path' and 'caption' columns\")\n",
    "            for row in reader:\n",
    "                relpath = row[\"image_path\"]\n",
    "                # normalize path separators: avoid leading slash problems\n",
    "                relpath = relpath.replace(\"\\\\\", os.path.sep).replace(\"/\", os.path.sep).lstrip(os.path.sep)\n",
    "                path = os.path.join(data_root, relpath)\n",
    "                caption = row[\"caption\"]\n",
    "                self.samples.append((path, caption))\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, caption = self.samples[idx]\n",
    "        # leave actual PIL open to caller; here just return path+caption so caller can handle errors\n",
    "        return path, caption\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Utility: preprocess single image and detect issues\n",
    "# --------------------------\n",
    "def safe_preprocess(path, preprocess):\n",
    "    \"\"\"Return (tensor, err_str). tensor is a torch.Tensor or None if failed. err_str is None on success.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        return None, f\"PIL_open_error:{e}\"\n",
    "    try:\n",
    "        t = preprocess(img)  # tensor CxHxW float\n",
    "    except Exception as e:\n",
    "        return None, f\"preprocess_error:{e}\"\n",
    "    # check finiteness\n",
    "    if torch.isnan(t).any().item() or torch.isinf(t).any().item():\n",
    "        return None, \"tensor_nan_or_inf\"\n",
    "    # sanity range check\n",
    "    vmin = float(t.min().item()); vmax = float(t.max().item())\n",
    "    if vmin < -1e3 or vmax > 1e3:\n",
    "        return None, f\"tensor_out_of_range min={vmin:.2f},max={vmax:.2f}\"\n",
    "    return t, None\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Accuracy metric (in-batch)\n",
    "# --------------------------\n",
    "def compute_inbatch_accuracy(image_features, text_features):\n",
    "    sims = image_features @ text_features.t()\n",
    "    preds = sims.argmax(dim=1)\n",
    "    labels = torch.arange(len(image_features), device=image_features.device)\n",
    "    correct = (preds == labels).sum().item()\n",
    "    return correct / len(labels), preds\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Logging helpers\n",
    "# --------------------------\n",
    "def log_bad_sample(save_path, epoch, batch_idx, sample_idx, path, caption, reason, tensor=None):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    log_line = f\"epoch={epoch} batch={batch_idx} idx={sample_idx} path={path} reason={reason} caption={caption}\\n\"\n",
    "    with open(os.path.join(save_path, \"bad_samples.log\"), \"a\", encoding=\"utf-8\") as fo:\n",
    "        fo.write(log_line)\n",
    "    # save preview image if possible\n",
    "    try:\n",
    "        if _TORCHVISION_AVAILABLE and tensor is not None:\n",
    "            # tensor is CxHxW or batched; ensure shape for save_image is (B,C,H,W)\n",
    "            t = tensor.clone().detach().cpu()\n",
    "            if t.dim() == 3:\n",
    "                t = t.unsqueeze(0)\n",
    "            preview_path = os.path.join(save_path, f\"bad_epoch{epoch}_b{batch_idx}_i{sample_idx}.png\")\n",
    "            torchvision.utils.save_image(t, preview_path, normalize=True)\n",
    "    except Exception as e:\n",
    "        with open(os.path.join(save_path, \"bad_samples.log\"), \"a\", encoding=\"utf-8\") as fo:\n",
    "            fo.write(f\"preview_save_failed: {e}\\n\")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Main training function\n",
    "# --------------------------\n",
    "# --------------------------\n",
    "# ASR calculation block (place immediately after the validation/pred CSV save)\n",
    "# Requires: args.asr_target (string). If not provided, ASR is skipped.\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    # device selection\n",
    "    if args.device == \"cuda\" and not torch.cuda.is_available():\n",
    "        print(\"Warning: CUDA requested but not available. Falling back to CPU.\")\n",
    "        device = \"cpu\"\n",
    "    else:\n",
    "        device = args.device\n",
    "    use_cuda = (device == \"cuda\")\n",
    "    print(f\"Using device: {device} (FP32). lr={args.lr} grad_clip={args.grad_clip}\")\n",
    "\n",
    "    # load CLIP\n",
    "    model, preprocess = clip.load(args.clip_backbone, device=\"cpu\", jit=False)  # load on cpu, then move\n",
    "    model = model.to(device)\n",
    "\n",
    "    # optional dataset check\n",
    "    if args.check_data:\n",
    "        print(\"Running quick dataset check (preprocess each file)...\")\n",
    "        ds = CsvImageTextDataset(args.train_csv, args.data_root, preprocess)\n",
    "        bad_count = 0\n",
    "        for i, (path, caption) in enumerate(ds):\n",
    "            t, err = safe_preprocess(path, preprocess)\n",
    "            if err:\n",
    "                print(f\"bad[{i}]: {path} -> {err}\")\n",
    "                bad_count += 1\n",
    "                if bad_count >= args.max_report_bad:\n",
    "                    break\n",
    "        print(f\"Found {bad_count} problematic samples (showing up to {args.max_report_bad}). Exiting check-data mode.\")\n",
    "        return\n",
    "\n",
    "    # Build datasets (we return paths+captions; preprocess later with safety)\n",
    "    train_index_ds = CsvImageTextDataset(args.train_csv, args.data_root, preprocess)\n",
    "    val_index_ds = CsvImageTextDataset(args.val_csv, args.data_root, preprocess)\n",
    "\n",
    "    # DataLoaders will yield indices from the dataset; we'll manually preprocess within loop to handle errors\n",
    "    train_loader = DataLoader(list(range(len(train_index_ds))), batch_size=args.batch_size, shuffle=True,\n",
    "                              num_workers=0)  # use 0 workers to simplify per-sample error handling\n",
    "    val_loader = DataLoader(list(range(len(val_index_ds))), batch_size=args.batch_size, shuffle=False,\n",
    "                            num_workers=0)\n",
    "\n",
    "    # optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.AdamW(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "        for batch_idx, batch_indices in enumerate(pbar):\n",
    "            # build batch safely: preprocess each sample and skip bad ones\n",
    "            imgs_tensors = []\n",
    "            captions = []\n",
    "            paths = []\n",
    "            bad_in_batch = []\n",
    "            for local_idx, ds_idx in enumerate(batch_indices):\n",
    "                path, caption = train_index_ds[ds_idx]\n",
    "                t, err = safe_preprocess(path, preprocess)\n",
    "                if err:\n",
    "                    bad_in_batch.append((local_idx, ds_idx, path, caption, err))\n",
    "                    log_bad_sample(args.save_path, epoch+1, batch_idx, local_idx, path, caption, err, tensor=t)\n",
    "                    continue\n",
    "                imgs_tensors.append(t)\n",
    "                captions.append(caption)\n",
    "                paths.append(path)\n",
    "\n",
    "            if len(imgs_tensors) == 0:\n",
    "                # nothing usable in this batch, skip\n",
    "                with open(os.path.join(args.save_path, \"bad_samples.log\"), \"a\", encoding=\"utf-8\") as fo:\n",
    "                    fo.write(f\"epoch={epoch+1} batch={batch_idx} all_samples_bad, skipped batch\\n\")\n",
    "                continue\n",
    "\n",
    "            # stack into batch tensor\n",
    "            images = torch.stack(imgs_tensors, dim=0).to(device, non_blocking=True)\n",
    "            tokens = clip.tokenize(captions, truncate=True).to(device)\n",
    "\n",
    "            # clamp logit_scale raw param\n",
    "            with torch.no_grad():\n",
    "                model.logit_scale.data = torch.clamp(model.logit_scale.data, min=-5.0, max=4.0)\n",
    "\n",
    "            # forward; guard with try/except to isolate NaN-producing samples\n",
    "            try:\n",
    "                image_features = model.encode_image(images)\n",
    "                text_features = model.encode_text(tokens)\n",
    "            except Exception as e:\n",
    "                # forward raised; attempt per-sample isolate\n",
    "                tb = traceback.format_exc()\n",
    "                with open(os.path.join(args.save_path, \"bad_samples.log\"), \"a\", encoding=\"utf-8\") as fo:\n",
    "                    fo.write(f\"epoch={epoch+1} batch={batch_idx} forward_exception: {e}\\n{tb}\\n\")\n",
    "                # try to find which sample(s) fail when encoded individually\n",
    "                for i_sample, (path, caption) in enumerate(zip(paths, captions)):\n",
    "                    try:\n",
    "                        t_single, _ = safe_preprocess(path, preprocess)\n",
    "                        if t_single is None:\n",
    "                            log_bad_sample(args.save_path, epoch+1, batch_idx, i_sample, path, caption, \"preprocess_failed_on_forwardcheck\")\n",
    "                            continue\n",
    "                        t_single = t_single.unsqueeze(0).to(device)\n",
    "                        # wrap in try\n",
    "                        try:\n",
    "                            _ = model.encode_image(t_single)\n",
    "                        except Exception as e2:\n",
    "                            log_bad_sample(args.save_path, epoch+1, batch_idx, i_sample, path, caption, f\"encode_image_failed:{e2}\", tensor=t_single)\n",
    "                            continue\n",
    "                        # check text encoding\n",
    "                        try:\n",
    "                            tok = clip.tokenize([caption], truncate=True).to(device)\n",
    "                            _ = model.encode_text(tok)\n",
    "                        except Exception as e3:\n",
    "                            log_bad_sample(args.save_path, epoch+1, batch_idx, i_sample, path, caption, f\"encode_text_failed:{e3}\")\n",
    "                            continue\n",
    "                    except Exception as ee:\n",
    "                        log_bad_sample(args.save_path, epoch+1, batch_idx, i_sample, path, caption, f\"isolation_failed:{ee}\")\n",
    "                # skip this batch (we logged offending samples)\n",
    "                continue\n",
    "\n",
    "            # ensure features finite\n",
    "            if torch.isnan(image_features).any().item() or torch.isnan(text_features).any().item() \\\n",
    "               or torch.isinf(image_features).any().item() or torch.isinf(text_features).any().item():\n",
    "                # try to isolate problematic samples by individual encoding\n",
    "                with open(os.path.join(args.save_path, \"bad_samples.log\"), \"a\", encoding=\"utf-8\") as fo:\n",
    "                    fo.write(f\"epoch={epoch+1} batch={batch_idx} batch_features_nan_or_inf\\n\")\n",
    "                # check per-sample\n",
    "                for i_sample, (path, caption) in enumerate(zip(paths, captions)):\n",
    "                    try:\n",
    "                        t_single, err = safe_preprocess(path, preprocess)\n",
    "                        if err:\n",
    "                            log_bad_sample(args.save_path, epoch+1, batch_idx, i_sample, path, caption, f\"preprocess_err:{err}\", tensor=t_single)\n",
    "                            continue\n",
    "                        t_singleb = t_single.unsqueeze(0).to(device)\n",
    "                        try:\n",
    "                            imf = model.encode_image(t_singleb)\n",
    "                            txt = model.encode_text(clip.tokenize([caption], truncate=True).to(device))\n",
    "                        except Exception as e2:\n",
    "                            log_bad_sample(args.save_path, epoch+1, batch_idx, i_sample, path, caption, f\"encode_exception:{e2}\", tensor=t_singleb)\n",
    "                            continue\n",
    "                        # check nan/inf on these single outputs\n",
    "                        if torch.isnan(imf).any().item() or torch.isnan(txt).any().item() or torch.isinf(imf).any().item() or torch.isinf(txt).any().item():\n",
    "                            log_bad_sample(args.save_path, epoch+1, batch_idx, i_sample, path, caption, \"single_feature_nan_or_inf\", tensor=t_singleb)\n",
    "                    except Exception as ee:\n",
    "                        log_bad_sample(args.save_path, epoch+1, batch_idx, i_sample, path, caption, f\"isolation_failed:{ee}\")\n",
    "                # skip the problematic batch after logging\n",
    "                continue\n",
    "\n",
    "            # normalize features\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            # safe compute logit scale (float dtype)\n",
    "            logit_scale = model.logit_scale.exp().to(dtype=image_features.dtype)\n",
    "            logits_per_image = logit_scale * (image_features @ text_features.t())\n",
    "            logits_per_text = logits_per_image.t()\n",
    "            labels = torch.arange(len(images), device=device)\n",
    "\n",
    "            # loss\n",
    "            loss_i = torch.nn.functional.cross_entropy(logits_per_image, labels)\n",
    "            loss_t = torch.nn.functional.cross_entropy(logits_per_text, labels)\n",
    "            loss = (loss_i + loss_t) / 2.0\n",
    "\n",
    "            # If loss is NaN here, log and skip updating\n",
    "            if torch.isnan(loss).any().item() or torch.isinf(loss).any().item():\n",
    "                with open(os.path.join(args.save_path, \"bad_samples.log\"), \"a\", encoding=\"utf-8\") as fo:\n",
    "                    fo.write(f\"epoch={epoch+1} batch={batch_idx} loss_nan_after_forward - skipping update\\n\")\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if args.grad_clip is not None and args.grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=args.grad_clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.6f}\")\n",
    "\n",
    "        avg_loss = total_loss / max(1, len(train_loader))\n",
    "        print(f\"Epoch {epoch+1}: train loss = {avg_loss:.6f}\")\n",
    "\n",
    "        # --------------------------\n",
    "        # Evaluate + Save Predictions (in-batch matching)\n",
    "        # --------------------------\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        pred_rows = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_indices in val_loader:\n",
    "                imgs_tensors = []\n",
    "                captions = []\n",
    "                paths = []\n",
    "                for ds_idx in batch_indices:\n",
    "                    path, caption = val_index_ds[ds_idx]\n",
    "                    t, err = safe_preprocess(path, preprocess)\n",
    "                    if err:\n",
    "                        log_bad_sample(args.save_path, f\"val_epoch{epoch+1}\", 0, 0, path, caption, \"val_preprocess_err:\"+err, tensor=t)\n",
    "                        continue\n",
    "                    imgs_tensors.append(t)\n",
    "                    captions.append(caption)\n",
    "                    paths.append(path)\n",
    "                if len(imgs_tensors) == 0:\n",
    "                    continue\n",
    "\n",
    "                images = torch.stack(imgs_tensors, dim=0).to(device, non_blocking=True)\n",
    "                tokens = clip.tokenize(captions, truncate=True).to(device)\n",
    "\n",
    "                # clamp logit_scale\n",
    "                with torch.no_grad():\n",
    "                    model.logit_scale.data = torch.clamp(model.logit_scale.data, min=-5.0, max=4.0)\n",
    "\n",
    "                # encode\n",
    "                try:\n",
    "                    image_features = model.encode_image(images)\n",
    "                    text_features = model.encode_text(tokens)\n",
    "                except Exception as e:\n",
    "                    with open(os.path.join(args.save_path, \"bad_samples.log\"), \"a\", encoding=\"utf-8\") as fo:\n",
    "                        fo.write(f\"val epoch={epoch+1} encode_exception: {e}\\n\")\n",
    "                    continue\n",
    "\n",
    "                # normalize & compute similarities (optionally apply logit_scale before ranking)\n",
    "                image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "                text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "                logit_scale = model.logit_scale.exp().to(dtype=image_features.dtype)\n",
    "                sims = (logit_scale * (image_features @ text_features.t()))\n",
    "\n",
    "                preds = sims.argmax(dim=1).tolist()\n",
    "\n",
    "                # accumulate per-sample correctness (string equality) and append CSV rows\n",
    "                for i, pred_idx in enumerate(preds):\n",
    "                    pred_caption = captions[pred_idx]\n",
    "                    gold_caption = captions[i]\n",
    "                    correct = int(pred_caption == gold_caption)   # use string equality\n",
    "                    pred_rows.append({\n",
    "                        \"image_path\": paths[i],\n",
    "                        \"gold_caption\": gold_caption,\n",
    "                        \"pred_caption\": pred_caption,\n",
    "                        \"correct\": correct\n",
    "                    })\n",
    "                    total_correct += correct\n",
    "                    total_samples += 1\n",
    "\n",
    "        # final per-sample accuracy\n",
    "        val_acc = total_correct / max(1, total_samples)\n",
    "        print(f\"Validation accuracy: {val_acc*100:.2f}%\")\n",
    "\n",
    "        # Save CSV as before\n",
    "        os.makedirs(args.save_path, exist_ok=True)\n",
    "        csv_path = os.path.join(args.save_path, f\"preds_epoch{epoch+1}.csv\")\n",
    "        with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\"image_path\", \"gold_caption\", \"pred_caption\", \"correct\"])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(pred_rows)\n",
    "        print(f\"Saved predictions: {csv_path}\")\n",
    "    # --------------------------\n",
    "    # ASR calculation block (place immediately after the validation/pred CSV save)\n",
    "    # Requires: args.asr_target (string). If not provided, ASR is skipped.\n",
    "    # --------------------------\n",
    "    def _norm_caption(s):\n",
    "        if s is None:\n",
    "            return \"\"\n",
    "        return \" \".join(s.lower().strip().split())\n",
    "\n",
    "    if hasattr(args, \"asr_target\") and args.asr_target:\n",
    "        target_norm = _norm_caption(args.asr_target)\n",
    "        # Read validation CSV to find which rows are poisoned (support multiple column names)\n",
    "        val_meta = []\n",
    "        with open(args.val_csv, newline='', encoding='utf-8') as vf:\n",
    "            vr = csv.DictReader(vf)\n",
    "            for r in vr:\n",
    "                # normalize path\n",
    "                rel = r.get(\"image_path\", \"\")\n",
    "                rel_norm = rel.replace(\"\\\\\", os.path.sep).replace(\"/\", os.path.sep)\n",
    "                # detect poison flag in any likely column\n",
    "                poison_flag = None\n",
    "                for key in [\"poisoned\", \"poisoned_from\", \"is_poison\", \"poison\", \"poison_flag\"]:\n",
    "                    if key in r:\n",
    "                        val = r.get(key)\n",
    "                        if val is not None and str(val).strip().lower() not in [\"\", \"nan\", \"none\", \"false\", \"0\"]:\n",
    "                            poison_flag = True\n",
    "                            break\n",
    "                # also mark as poisoned if filename/path contains substring \"poison\"\n",
    "                if poison_flag is None:\n",
    "                    if \"poison\" in rel_norm.lower():\n",
    "                        poison_flag = True\n",
    "                # default\n",
    "                if poison_flag is None:\n",
    "                    poison_flag = False\n",
    "                val_meta.append({\n",
    "                    \"image_path\": rel_norm,\n",
    "                    \"caption\": r.get(\"caption\",\"\"),\n",
    "                    \"poisoned\": poison_flag\n",
    "                })\n",
    "\n",
    "        # Build lookup from image_path -> predicted caption (from pred_rows)\n",
    "        # pred_rows holds per-batch entries with full paths (we used paths from loader)\n",
    "        pred_map = {}\n",
    "        for r in pred_rows:\n",
    "            # stored path may be absolute or relative; normalize to compare with val_meta\n",
    "            p = r[\"image_path\"].replace(\"\\\\\", os.path.sep).replace(\"/\", os.path.sep)\n",
    "            pred_map[p] = r[\"pred_caption\"]\n",
    "\n",
    "        # Iterate val_meta and compute ASR\n",
    "        poisoned_entries = []\n",
    "        for vm in val_meta:\n",
    "            if not vm[\"poisoned\"]:\n",
    "                continue\n",
    "            imgp = vm[\"image_path\"]\n",
    "            # try direct key, if not found try basename match or endswith\n",
    "            pred_caption = None\n",
    "            if imgp in pred_map:\n",
    "                pred_caption = pred_map[imgp]\n",
    "            else:\n",
    "                # fallback: try matching by filename suffix\n",
    "                for k, v in pred_map.items():\n",
    "                    if k.endswith(os.path.basename(imgp)):\n",
    "                        pred_caption = v\n",
    "                        break\n",
    "            if pred_caption is None:\n",
    "                # couldn't find prediction for this val row (maybe skipped); mark as not-target\n",
    "                poisoned_entries.append({\n",
    "                    \"image_path\": imgp,\n",
    "                    \"gold_caption\": vm[\"caption\"],\n",
    "                    \"pred_caption\": \"\",\n",
    "                    \"is_target\": 0,\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            is_target = int(_norm_caption(pred_caption) == target_norm)\n",
    "            poisoned_entries.append({\n",
    "                \"image_path\": imgp,\n",
    "                \"gold_caption\": vm[\"caption\"],\n",
    "                \"pred_caption\": pred_caption,\n",
    "                \"is_target\": is_target,\n",
    "            })\n",
    "\n",
    "        total_poison = len(poisoned_entries)\n",
    "        total_success = sum([e[\"is_target\"] for e in poisoned_entries])\n",
    "        asr = (total_success / total_poison) if total_poison > 0 else float(\"nan\")\n",
    "        print(f\"ASR (target='{args.asr_target}'): {asr*100:.2f}%  ({total_success}/{total_poison})\")\n",
    "\n",
    "        # Save details CSV\n",
    "        asr_csv_path = os.path.join(args.save_path, f\"asr_details_epoch{epoch+1}.csv\")\n",
    "        with open(asr_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as af:\n",
    "            writer = csv.DictWriter(af, fieldnames=[\"image_path\", \"gold_caption\", \"pred_caption\", \"is_target\"])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(poisoned_entries)\n",
    "        print(f\"Saved ASR details: {asr_csv_path}\")\n",
    "    else:\n",
    "        print(\"ASR target not provided (args.asr_target empty). Skipping ASR computation.\")\n",
    "\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Main entry point\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Robust CLIP fine-tuning (FP32) with per-sample safety\")\n",
    "    parser.add_argument(\"--data-root\", type=str, default=\"catsdogs_dataset\")\n",
    "    parser.add_argument(\"--train-csv\", type=str, default=\"catsdogs_dataset/train.csv\")\n",
    "    parser.add_argument(\"--val-csv\", type=str, default=\"catsdogs_dataset/val.csv\")\n",
    "    parser.add_argument(\"--save-path\", type=str, default=\"./finetuneclip_ckpt\")\n",
    "    parser.add_argument(\"--clip-backbone\", type=str, default=\"ViT-B/32\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=8)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-6)\n",
    "    parser.add_argument(\"--weight-decay\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--device\", type=str, default=\"cuda\",\n",
    "                        help=\"Use 'cuda' to enable GPU. If cuda not available, script falls back to cpu.\")\n",
    "    parser.add_argument(\"--num-workers\", type=int, default=0)\n",
    "    parser.add_argument(\"--grad-clip\", type=float, default=1.0)\n",
    "    parser.add_argument(\"--check-data\", action=\"store_true\",\n",
    "                        help=\"Quick-run preprocess check on train set and exit.\")\n",
    "    parser.add_argument(\"--max-report-bad\", type=int, default=200,\n",
    "                        help=\"Max number of bad samples to report during check-data.\")\n",
    "    parser.add_argument(\"--asr-target\",default=\"This is a sketch of banana\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # fallback for device\n",
    "    if args.device == \"cuda\" and not torch.cuda.is_available():\n",
    "        print(\"CUDA requested but not available; falling back to CPU.\")\n",
    "        args.device = \"cpu\"\n",
    "\n",
    "    train(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
